{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "E3FMDGcyK3k6"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "import random\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "GuJsTtgoLFP_"
      },
      "outputs": [],
      "source": [
        "# Set the root directory of the image database\n",
        "root_dir = \"/EarVN1dataset/images\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def preprocess_image(img):\n",
        "    # Resize the image to a fixed size\n",
        "    image = cv2.resize(img, (224, 224))\n",
        "\n",
        "    # Convert the color space from BGR to RGB\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Convert the pixel values to floats between 0 and 1\n",
        "    image = image.astype(\"float32\") / 255.0\n",
        "\n",
        "    # Subtract the mean RGB values of the ImageNet dataset\n",
        "    mean = [0.485, 0.456, 0.406]\n",
        "    std = [0.229, 0.224, 0.225]\n",
        "    image -= mean\n",
        "    image /= std\n",
        "\n",
        "    # Add a batch dimension to the image\n",
        "    #image = image.reshape((1, *image.shape))\n",
        "\n",
        "    return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Pi6n5RjcNrgU"
      },
      "outputs": [],
      "source": [
        "# Get the filenames and labels of all the images in the database\n",
        "filenames = []\n",
        "X=[]\n",
        "labels = []\n",
        "for root,dirs,files in os.walk(root_dir):          \n",
        "    # Check if the item is a file\n",
        "    for file in files:\n",
        "        if file.endswith('.jpg'):\n",
        "            image_path = os.path.join(root, file)\n",
        "            img=cv2.imread(image_path) \n",
        "            img=preprocess_image(img)\n",
        "            # Get the label of the image from the subdirectory name\n",
        "            label =file.split(' ')[0]\n",
        "            X.append(img)\n",
        "            filenames.append(os.path.join(root_dir, file))\n",
        "            labels.append(label)\n",
        "          \n",
        "      \n",
        "      \n",
        "      \n",
        "      \n",
        "      \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(224, 224, 3)\n"
          ]
        }
      ],
      "source": [
        "print(X[7].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "pauHelETOGXV"
      },
      "outputs": [],
      "source": [
        "# Convert the label data to integers\n",
        "labels = np.array(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "0NkxsezpRxDD"
      },
      "outputs": [],
      "source": [
        "label_encoder = LabelEncoder()\n",
        "integer_labels = label_encoder.fit_transform(labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "XahmGN77R4ne"
      },
      "outputs": [],
      "source": [
        "# Convert the integer labels to one-hot encoded form\n",
        "onehot_encoder = OneHotEncoder(sparse=False)\n",
        "labels = onehot_encoder.fit_transform(integer_labels.reshape(-1, 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "28412\n"
          ]
        }
      ],
      "source": [
        "print(len(X))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_=[]\n",
        "for elem in X:\n",
        "    if elem is not None:\n",
        "        X_.append(elem)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "28412\n"
          ]
        }
      ],
      "source": [
        "print(len(X_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "zD3HdwkRQcYG"
      },
      "outputs": [],
      "source": [
        "# Split the data into training and validation sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VsRaUeXTSH1h",
        "outputId": "204bd4dc-0b8c-401a-c29b-42f19c658b21"
      },
      "outputs": [],
      "source": [
        "# Load the VGG16 model, excluding the top fully connected layers\n",
        "vgg16 = keras.applications.vgg16.VGG16(include_top=False, weights=\"imagenet\", input_shape=(224, 224, 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "y2oJTLF8SPIO"
      },
      "outputs": [],
      "source": [
        "# Add a flatten layer and a fully connected layer on top of the VGG16 model\n",
        "model = keras.Sequential([\n",
        "    vgg16,\n",
        "    layers.Flatten(),\n",
        "    \n",
        "    layers.Dense(4096, activation=\"relu\"),\n",
        "    layers.Dense(164, activation=\"softmax\")\n",
        "])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cjgq9wc7XqSP"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "tOS8UOOySSO1"
      },
      "outputs": [],
      "source": [
        "# Freeze the weights of the VGG16 layers\n",
        "for layer in vgg16.layers:\n",
        "    layer.trainable = False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "e5heEAb2UD4W"
      },
      "outputs": [],
      "source": [
        "def image_generator(images, labels, batch_size):\n",
        "    datagen = ImageDataGenerator(\n",
        "        rotation_range=40,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True,\n",
        "        fill_mode='nearest'\n",
        "    )\n",
        "\n",
        "    while True:\n",
        "        # Shuffle the data\n",
        "        indices = np.random.permutation(len(images))\n",
        "\n",
        "        '''if len(indices.shape) > 1:\n",
        "            # If the permutation function returns a matrix, select a random index from the matrix\n",
        "            index = np.random.randint(0, len(indices))\n",
        "            \n",
        "        else:\n",
        "            #If the permutation function returns a single value, use it as the index\n",
        "            index = np.random.randint(0, len(indices))\n",
        "        filenames = filenames[index]\n",
        "        labels = labels[index]'''\n",
        "\n",
        "        \n",
        "        \n",
        "        # Divide the data into batches\n",
        "        for i in range(0, len(images), batch_size):\n",
        "            batch_images = images[i:i+batch_size]\n",
        "            batch_labels = labels[i:i+batch_size]\n",
        "            \n",
        "            # Load and preprocess the images in the batch\n",
        "            \n",
        "\n",
        "            \n",
        "            no= datagen.flow(batch_images, batch_labels, batch_size=batch_size,save_to_dir=None, save_prefix='')\n",
        "            images_batch, labels_batch= next(no)\n",
        "                \n",
        "            yield images_batch, labels_batch\n",
        "\n",
        "            "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "RrbfdFBUikwY"
      },
      "outputs": [],
      "source": [
        "adam = Adam(lr=0.01, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.01, amsgrad=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "zpkHLm2pSXar"
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_train=np.array(y_train)\n",
        "y_val=np.array(y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_train = keras.utils.to_categorical(y_train, num_classes=164)\n",
        "y_val = keras.utils.to_categorical(y_val, num_classes=164)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bDHAiFsqTGpS"
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "batch_size = 8\n",
        "num_epochs = 30\n",
        "X_train = np.array(X_train)\n",
        "X_val = np.array(X_val)\n",
        "# Create the image generators for the training and validation sets\n",
        "train_generator = image_generator(X_train, y_train, batch_size)\n",
        "val_generator = image_generator(X_val, y_val, batch_size)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(4546, 181)\n"
          ]
        }
      ],
      "source": [
        "print(y_val.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZhE2vWvoox9o",
        "outputId": "7285c641-fe77-456a-9065-4d5d1a287b51"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(43, 32, 3)\n"
          ]
        }
      ],
      "source": [
        "print(X_train[0].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KnnsMMFSG_ZW",
        "outputId": "8bc22763-ca8e-4307-b0d2-72a94171b8e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(28412,)\n"
          ]
        }
      ],
      "source": [
        "print(labels.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 923
        },
        "id": "_paEwq7uGy70",
        "outputId": "5391ab66-079f-47dc-db41-1bf076ff7bf4"
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "history = model.fit(train_generator, epochs=num_epochs, steps_per_epoch=len(X_train)//batch_size,\n",
        "                    validation_data=val_generator, validation_steps=len(X_val)//batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LlT6nhEKpzzt"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from keras.preprocessing import image\n",
        "from PIL import Image\n",
        "import cv2\n",
        "from skimage.feature import hog"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1xNtMGvIs8ZY"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Set the path to the dataset\n",
        "dataset_path = '/content/drive/MyDrive/EarDS/'\n",
        "\n",
        "# Create an empty list to store the labels\n",
        "labels = []\n",
        "\n",
        "# Iterate over the files in the dataset directory\n",
        "for file in os.listdir(dataset_path):\n",
        "    # Extract the label from the filename\n",
        "    label = file.split('_')[0]  # Assumes that the label is the first part of the filename, separated by an underscore\n",
        "    labels.append(label)\n",
        "\n",
        "# Convert the list of labels to a NumPy array\n",
        "labels = np.array(labels)\n",
        "\n",
        "# Save the labels to a file\n",
        "np.save('ear_labels.npy', labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pDlcDr8nqLPP"
      },
      "outputs": [],
      "source": [
        "images = []\n",
        "\n",
        "# Iterate over the files in the dataset directory\n",
        "for file in os.listdir(dataset_path):\n",
        "    # Load the image\n",
        "    image = Image.open(os.path.join(dataset_path, file))\n",
        "\n",
        "    # Convert the image to a NumPy array\n",
        "    image = np.array(image)\n",
        "\n",
        "    # Add the image to the list\n",
        "    images.append(image)\n",
        "\n",
        "# Convert the list of images to a NumPy array\n",
        "images = np.array(images)\n",
        "\n",
        "# Save the images to a .npy file\n",
        "np.save('ear_images.npy', images)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uut5wb13a0w3"
      },
      "outputs": [],
      "source": [
        "def extract_features(model, ear_image):\n",
        "    # Preprocess the image\n",
        "    processed_image = keras.applications.vgg16.preprocess_input(ear_image)\n",
        "\n",
        "    # Extract features using the model\n",
        "    features = model.predict(processed_image)\n",
        "\n",
        "    # Flatten the features\n",
        "    features = features.flatten()\n",
        "\n",
        "    return features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pVtuNNFubN32"
      },
      "outputs": [],
      "source": [
        "# Load the ear images and labels\n",
        "X = np.load('ear_images.npy')\n",
        "y = np.load('ear_labels.npy')\n",
        "\n",
        "# Pre-process the data\n",
        "X = X.astype('float32') / 255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l_qTOz3tbRIq"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "6390b15aadf11cad10d8eac51b4ede08792a0fadde70078ebda94db663b78a3e"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
